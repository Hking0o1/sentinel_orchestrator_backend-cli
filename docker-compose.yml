# This is the master file that defines and runs our entire multi-container application.
version: '3.8'

services:
  # --- 1. NGINX Reverse Proxy (The "Gatehouse") ---
  proxy:
    build:
      context: ./proxy
      dockerfile: Dockerfile.proxy
    ports:
      - "80:80"
    depends_on:
      - backend
    networks:
      - sentinel_net

  # --- 2. FastAPI Backend API (The "Fortress") ---
  backend:
    build:
      context: .
      dockerfile: Dockerfile.backend
    env_file:
      - .env
    volumes:
      # Use a bind mount for scan results
      - ./scan_results:/app/scan_results
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - sentinel_net

  # --- 3. Celery Scanner Worker (The "Engine") ---
  worker:
    build:
      context: .
      dockerfile: Dockerfile.worker
      args:
        NVD_API_KEY: ${NVD_API_KEY}
    env_file:
      - .env
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./scan_results:/app/scan_results
      # REPLACE this with the absolute path to your projects folder
      - "C:/Users/Lenovo/Desktop/scannable_projects:/app/projects_to_scan"
    depends_on:
      - backend
      - redis
    networks:
      - sentinel_net
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # --- 4. NEW: Celery Beat Scheduler (The "Heartbeat") ---
  beat:
    build:
      context: .
      dockerfile: Dockerfile.worker # Use the same image as the worker
    env_file:
      - .env
    volumes:
      # Mount the scan results to store the beat schedule file
      - ./scan_results:/app/scan_results
    depends_on:
      - backend
      - redis
    networks:
      - sentinel_net
    # This is the only difference: the command.
    # It starts the 'beat' scheduler instead of a 'worker'.
    # It will store its schedule file in our persistent volume.
    command: >
      sh -c "celery -A scanner.tasks.celery_app beat 
             --loglevel=info 
             --schedule=/app/scan_results/celerybeat-schedule"
    
  # --- 5. Redis Cache & Message Broker ---
  redis:
    image: redis:7-alpine
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - sentinel_net
    volumes:
      - redis_data:/data

  # --- 6. PostgreSQL Database ---
  db:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - sentinel_net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
    ports:
      - "5432:5432"

# --- Define Networks ---
networks:
  sentinel_net:
    driver: bridge

# --- Define Persistent Volumes ---
volumes:
  redis_data:
  postgres_data:
  # scan_results is now a bind mount